{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99cea58c-48bc-4af6-8358-df9695659983",
   "metadata": {},
   "source": [
    "# OpenAI Assistant Agent\n",
    "<a href=\"https://colab.research.google.com/github/run-llama/llama_index/blob/main/docs/examples/agent/openai_assistant_agent.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>\n",
    "\n",
    "This shows you how to use our agent abstractions built on top of the [OpenAI Assistant API](https://platform.openai.com/docs/assistants/overview).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c61c873d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install llama-index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54b7bc2e-606f-411a-9490-fcfab9236dfc",
   "metadata": {},
   "source": [
    "## Simple Agent (no external tools)\n",
    "\n",
    "Here we show a simple example with the built-in code interpreter."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e80e5b-aaee-4f23-b338-7ae62b08141f",
   "metadata": {},
   "source": [
    "Let's start by importing some simple building blocks.  "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "41101795",
   "metadata": {},
   "source": [
    "If you're opening this Notebook on colab, you will probably need to install LlamaIndex 🦙.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f856af7-2f11-446a-9aef-21d68ddf2695",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.agent import OpenAIAssistantAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b6fe26-0bdd-44ab-a887-9525dbc85f00",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = OpenAIAssistantAgent.from_new(\n",
    "    name=\"Math Tutor\",\n",
    "    instructions=\"You are a personal math tutor. Write and run code to answer math questions.\",\n",
    "    openai_tools=[{\"type\": \"code_interpreter\"}],\n",
    "    instructions_prefix=\"Please address the user as Jane Doe. The user has a premium account.\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40da2dd6-0872-4179-bbc1-33dfbb6c2b46",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'thread_ctzN0ZY3JUWETHhYxI3DiFSo'"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent.thread_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0433d6-d662-4d9c-a087-d2052269c4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent.chat(\n",
    "    \"I need to solve the equation `3x + 11 = 14`. Can you help me?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bfaa306-245a-43e3-bcd4-f5ad8611aa70",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The solution to the equation \\(3x + 11 = 14\\) is \\(x = 1\\).\n"
     ]
    }
   ],
   "source": [
    "print(str(response))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b8a07e-b18d-4ab2-be61-9f5b835aface",
   "metadata": {},
   "source": [
    "## Assistant with Query Engine Tools\n",
    "\n",
    "Here we showcase the function calling capabilities of the OpenAIAssistantAgent by integrating it with our query engine tools over different documents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62c55f5f-fc22-4e85-b539-fbbe1fd93ac2",
   "metadata": {},
   "source": [
    "### 1. Setup: Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "355abef5-85c2-4a2c-8b6f-3a6c2d520807",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.agent import OpenAIAssistantAgent\n",
    "from llama_index import (\n",
    "    SimpleDirectoryReader,\n",
    "    VectorStoreIndex,\n",
    "    StorageContext,\n",
    "    load_index_from_storage,\n",
    ")\n",
    "\n",
    "from llama_index.tools import QueryEngineTool, ToolMetadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6d02c34-d5d6-4318-824f-1ae20fc5d286",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    storage_context = StorageContext.from_defaults(\n",
    "        persist_dir=\"./storage/lyft\"\n",
    "    )\n",
    "    lyft_index = load_index_from_storage(storage_context)\n",
    "\n",
    "    storage_context = StorageContext.from_defaults(\n",
    "        persist_dir=\"./storage/uber\"\n",
    "    )\n",
    "    uber_index = load_index_from_storage(storage_context)\n",
    "\n",
    "    index_loaded = True\n",
    "except:\n",
    "    index_loaded = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b43c5eb8-a98b-4f17-877b-f66b7d8715ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2023-11-07 00:20:08--  https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/10k/uber_2021.pdf\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 2606:50c0:8000::154, 2606:50c0:8001::154, 2606:50c0:8002::154, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8000::154|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1880483 (1.8M) [application/octet-stream]\n",
      "Saving to: ‘data/10k/uber_2021.pdf’\n",
      "\n",
      "data/10k/uber_2021. 100%[===================>]   1.79M  --.-KB/s    in 0.07s   \n",
      "\n",
      "2023-11-07 00:20:08 (24.3 MB/s) - ‘data/10k/uber_2021.pdf’ saved [1880483/1880483]\n",
      "\n",
      "--2023-11-07 00:20:08--  https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/10k/lyft_2021.pdf\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 2606:50c0:8000::154, 2606:50c0:8001::154, 2606:50c0:8002::154, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|2606:50c0:8000::154|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 1440303 (1.4M) [application/octet-stream]\n",
      "Saving to: ‘data/10k/lyft_2021.pdf’\n",
      "\n",
      "data/10k/lyft_2021. 100%[===================>]   1.37M  --.-KB/s    in 0.06s   \n",
      "\n",
      "2023-11-07 00:20:09 (22.2 MB/s) - ‘data/10k/lyft_2021.pdf’ saved [1440303/1440303]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!mkdir -p 'data/10k/'\n",
    "!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/10k/uber_2021.pdf' -O 'data/10k/uber_2021.pdf'\n",
    "!wget 'https://raw.githubusercontent.com/run-llama/llama_index/main/docs/examples/data/10k/lyft_2021.pdf' -O 'data/10k/lyft_2021.pdf'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d79f4f2-bc1d-4aff-b51e-0f05e4de2aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not index_loaded:\n",
    "    # load data\n",
    "    lyft_docs = SimpleDirectoryReader(\n",
    "        input_files=[\"./data/10k/lyft_2021.pdf\"]\n",
    "    ).load_data()\n",
    "    uber_docs = SimpleDirectoryReader(\n",
    "        input_files=[\"./data/10k/uber_2021.pdf\"]\n",
    "    ).load_data()\n",
    "\n",
    "    # build index\n",
    "    lyft_index = VectorStoreIndex.from_documents(lyft_docs)\n",
    "    uber_index = VectorStoreIndex.from_documents(uber_docs)\n",
    "\n",
    "    # persist index\n",
    "    lyft_index.storage_context.persist(persist_dir=\"./storage/lyft\")\n",
    "    uber_index.storage_context.persist(persist_dir=\"./storage/uber\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df845e8-8932-4a51-ad0a-db0e6533fdc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "lyft_engine = lyft_index.as_query_engine(similarity_top_k=3)\n",
    "uber_engine = uber_index.as_query_engine(similarity_top_k=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69ed3f3b-cf01-4958-ba53-e5448e487c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine_tools = [\n",
    "    QueryEngineTool(\n",
    "        query_engine=lyft_engine,\n",
    "        metadata=ToolMetadata(\n",
    "            name=\"lyft_10k\",\n",
    "            description=(\n",
    "                \"Provides information about Lyft financials for year 2021. \"\n",
    "                \"Use a detailed plain text question as input to the tool.\"\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    "    QueryEngineTool(\n",
    "        query_engine=uber_engine,\n",
    "        metadata=ToolMetadata(\n",
    "            name=\"uber_10k\",\n",
    "            description=(\n",
    "                \"Provides information about Uber financials for year 2021. \"\n",
    "                \"Use a detailed plain text question as input to the tool.\"\n",
    "            ),\n",
    "        ),\n",
    "    ),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcd18ac7-5b5b-4093-8882-30ab93fa9d16",
   "metadata": {},
   "source": [
    "### 2. Let's Try it Out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e76a5a96-c299-4565-bc1a-8b4f4ca4b455",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = OpenAIAssistantAgent.from_new(\n",
    "    name=\"SEC Analyst\",\n",
    "    instructions=\"You are a QA assistant designed to analyze sec filings.\",\n",
    "    tools=query_engine_tools,\n",
    "    instructions_prefix=\"Please address the user as Jerry.\",\n",
    "    verbose=True,\n",
    "    run_retrieve_sleep_time=1.0,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b30b508-3f2e-47e6-b79c-57333fe37e88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Calling Function ===\n",
      "Calling function: lyft_10k with args: {\"input\":\"What was Lyft's revenue growth in 2021?\"}\n",
      "Got output: Lyft's revenue growth in 2021 was 36%.\n",
      "========================\n"
     ]
    }
   ],
   "source": [
    "response = agent.chat(\"What was Lyft's revenue growth in 2021?\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0783a8db-5546-472a-8376-6d2774dba45a",
   "metadata": {},
   "source": [
    "## Assistant with Built-In Retrieval\n",
    "\n",
    "Let's test the assistant by having it use the built-in OpenAI Retrieval tool over a user-uploaded file.\n",
    "\n",
    "Here, we upload and pass in the file during assistant-creation time. \n",
    "\n",
    "The other option is you can upload/pass the file-id in for a message in a given thread with `upload_files` and `add_message`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac4421f-ca9e-4d9f-91e1-10e1fb1119e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.agent import OpenAIAssistantAgent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304c5c23-930c-4aed-8e0b-84a6e5c36138",
   "metadata": {},
   "outputs": [],
   "source": [
    "agent = OpenAIAssistantAgent.from_new(\n",
    "    name=\"SEC Analyst\",\n",
    "    instructions=\"You are a QA assistant designed to analyze sec filings.\",\n",
    "    openai_tools=[{\"type\": \"retrieval\"}],\n",
    "    instructions_prefix=\"Please address the user as Jerry.\",\n",
    "    files=[\"data/10k/lyft_2021.pdf\"],\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6845f8e9-ca2c-4bd1-a31a-dc58b47c585a",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = agent.chat(\"What was Lyft's revenue growth in 2021?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a93a9d-cc97-49c4-8a12-de710edc2fac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lyft's revenue increased by $843.6 million or 36% in 2021 as compared to the previous year【7†source】.\n"
     ]
    }
   ],
   "source": [
    "print(str(response))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llama_index_v2",
   "language": "python",
   "name": "llama_index_v2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
